{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET = 'NSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import asyncio\n",
    "\n",
    "from ib_insync import IB, util, Option, MarketOrder, Contract\n",
    "from typing import Callable, Coroutine, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific to Jupyter. Will be ignored in IDE / command-lines\n",
    "import IPython as ipy\n",
    "if ipy.get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    util.startLoop()\n",
    "    pd.options.display.max_columns = None\n",
    "    \n",
    "    THIS_FOLDER = '' # Dummy for jupyter notebook's current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get capability to import programs from `asyncib` folder\n",
    "cwd = pathlib.Path.cwd() # working directory from where python was initiated\n",
    "DATAPATH = cwd.joinpath('data', MARKET.lower()) # path to store data files\n",
    "LOGFILE = DATAPATH.joinpath('temp.log') # path to store log files\n",
    "\n",
    "IBPATH = cwd.parent.parent.joinpath('asyncib') # where ib programs are stored\n",
    "\n",
    "# append IBPATH to import programs.\n",
    "if str(IBPATH) not in sys.path:  # Convert it to string!\n",
    "    sys.path.append(str(IBPATH))\n",
    "    \n",
    "IBDATAPATH = IBPATH.joinpath('data', MARKET.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the host, port, cid\n",
    "from engine import Vars\n",
    "\n",
    "ibp = Vars(MARKET.upper())  # IB Parameters from var.yml\n",
    "HOST, PORT, CID = ibp.HOST, ibp.PORT, ibp.CID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dfrq.pkl',\n",
       " 'df_chains.pkl',\n",
       " 'df_fresh.pkl',\n",
       " 'df_ohlcs.pkl',\n",
       " 'df_opt_margins.pkl',\n",
       " 'df_opt_prices.pkl',\n",
       " 'df_symlots.pkl',\n",
       " 'df_unds.pkl',\n",
       " 'df_und_margins.pkl',\n",
       " 'qopts.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the pickle files\n",
    "from os import listdir\n",
    "fs = listdir(DATAPATH)\n",
    "\n",
    "files = [f for f in fs if f[-4:] == '.pkl']\n",
    "for f in files:\n",
    "    exec(f\"{f.split('.')[0]} = pd.read_pickle(DATAPATH.joinpath(f))\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing `Fresh`\n",
    "(Refactoring Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import qualify, executeAsync, margin, save_df, price\n",
    "from support import Timer, quick_pf, get_dte, calcsdmult_df, get_prec\n",
    "from dfrq import get_dfrq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fresh started at 18-Nov-2020 14:25:26\n",
      "Wall time: 426 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ibp = Vars(MARKET.upper())  # IB Parameters from var.yml\n",
    "\n",
    "HOST, PORT, CID = ibp.HOST, ibp.PORT, ibp.CID\n",
    "\n",
    "LOGPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", \"log\")\n",
    "DATAPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", MARKET.lower())\n",
    "\n",
    "# * SETUP LOGS AND CLEAR THEM\n",
    "LOGFILE = LOGPATH.joinpath(MARKET.lower() + \"_fresh.log\")\n",
    "util.logToFile(path=LOGFILE, level=30)\n",
    "with open(LOGFILE, \"w\"):\n",
    "    pass\n",
    "\n",
    "# . start the time\n",
    "fresh_time = Timer('Fresh')\n",
    "fresh_time.start()\n",
    "\n",
    "# * LOAD FILES\n",
    "qopts = pd.read_pickle(DATAPATH.joinpath('qopts.pkl'))\n",
    "df_chains = pd.read_pickle(DATAPATH.joinpath('df_chains.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unds = pd.read_pickle(DATAPATH.joinpath('df_unds.pkl'))\n",
    "df_unds = get_unds(MARKET, und_cts, savedf=True)\n",
    "\n",
    "# * GET dfrq\n",
    "dfrq = get_dfrq(MARKET)\n",
    "fresh = set(dfrq[dfrq.status == 'fresh'].symbol)\n",
    "\n",
    "# . generate df_opts from qopts.pkl\n",
    "optcols = \"conId,symbol,secType,lastTradeDateOrContractMonth,strike,right\".split(\",\")\n",
    "df_opts = util.df(qopts.to_list())[optcols].rename(columns={\"lastTradeDateOrContractMonth\": \"expiry\"})\n",
    "\n",
    "qo_dict = {int(q.conId): q for q in qopts}\n",
    "df_opts['contract'] = df_opts.conId.map(qo_dict)\n",
    "\n",
    "df_opts = df_opts.dropna(subset=['contract']).reset_index(drop=True) # Remove NaN in contracts!\n",
    "\n",
    "# * BUILD df_fresh AND SCRUB IT UP\n",
    "\n",
    "# . build df_fresh\n",
    "df_fresh = df_opts[df_opts.symbol.isin(fresh)]\n",
    "\n",
    "df_fresh = df_fresh[~df_fresh.symbol.isin(ibp.BLACKLIST)] # remove blacklist\n",
    "\n",
    "# . remove dtes\n",
    "df_fresh.insert(3, 'dte', df_fresh.expiry.apply(get_dte))\n",
    "df_fresh = df_fresh[df_fresh.dte.between(ibp.MINDTE, ibp.MAXDTE, inclusive = True)]\n",
    "\n",
    "# .remove options within stdev fence\n",
    "\n",
    "# . integrate undPrice and und_iv\n",
    "df_fresh = df_fresh.set_index('symbol').\\\n",
    "            join(df_unds.set_index('symbol')[['iv', 'undPrice']]).\\\n",
    "                reset_index()\n",
    "\n",
    "# . compute One stdev\n",
    "df_fresh = df_fresh.assign(sd1 = df_fresh.undPrice * df_fresh.iv * (df_fresh.dte/365).apply(math.sqrt))\n",
    "\n",
    "hi_sd = df_fresh.undPrice + df_fresh.sd1 * ibp.CALLSTDMULT\n",
    "lo_sd = df_fresh.undPrice - df_fresh.sd1 * ibp.PUTSTDMULT\n",
    "\n",
    "df_fresh = df_fresh.assign(hi_sd = hi_sd, lo_sd = lo_sd)\n",
    "\n",
    "# . remove options within stdev fence\n",
    "fence_mask = ((df_fresh.strike > hi_sd) & (df_fresh.right == 'C')) | \\\n",
    "             ((df_fresh.strike < lo_sd) & (df_fresh.right == 'P'))\n",
    "\n",
    "df_fresh = df_fresh[fence_mask]\n",
    "\n",
    "# .remove options outside of remqty / MAXOPTQTY_SYM\n",
    "# .... map symbol to remqty\n",
    "remq = dfrq.set_index('symbol').remq.to_dict()\n",
    "\n",
    "# ... limit remqty to MAXOPTQTY_SYM\n",
    "remq = {k: min(v, ibp.MAXOPTQTY_SYM) for k, v in remq.items()}\n",
    "\n",
    "# ... sort and pick top options around the fence [ref: https://stackoverflow.com/questions/64864630]\n",
    "# . reverse strike for Calls to get the right sort order for top values\n",
    "df = df_fresh.assign(value=np.where(df_fresh.right=='C', -1*df_fresh.strike, df_fresh.strike))\n",
    "\n",
    "# . build cumcount series with index aligned to df\n",
    "s = (df.sort_values(['symbol', 'dte', 'value']).groupby(['symbol', 'dte', 'right'])).cumcount().reindex(df.index)\n",
    "\n",
    "# . get remq for symbols from df/series and pick up the top cumcounts\n",
    "df_fresh1 = df[s<df.symbol.map(remq)]\\\n",
    "            .sort_values(['symbol', 'dte', 'value'], ascending=[True, True, False])\\\n",
    "            .drop('value', 1).reset_index(drop=True)\n",
    "\n",
    "# . remove sd1 and rename `iv` to `und_iv`\n",
    "df_fresh1 = df_fresh1.drop('sd1', 1).rename(columns={'iv': 'und_iv'})\n",
    "\n",
    "# . integrate lots\n",
    "idx_cols = ['symbol', 'expiry', 'strike']\n",
    "df_fresh1 = df_fresh1.set_index(idx_cols).join(df_chains.set_index(idx_cols).lot).reset_index()\n",
    "\n",
    "# * GET PRICE, IV AND MARGIN OF OPTIONS AND INTEGRATE\n",
    "\n",
    "opt_pm_time = Timer('Option price and margin')\n",
    "opt_pm_time.start()\n",
    "\n",
    "fresh_contracts = df_fresh1.contract.to_list()\n",
    "fresh_orders = [MarketOrder(\"SELL\", lot / lot)\n",
    "                if MARKET.upper() == \"SNP\"\n",
    "                    else MarketOrder(\"SELL\", lot)\n",
    "                for lot in df_fresh1.lot]\n",
    "\n",
    "# . get fresh option price and iv\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_opt_prices = ib.run(\n",
    "        executeAsync(\n",
    "            ib=ib,\n",
    "            algo=price,\n",
    "            cts=fresh_contracts,\n",
    "            CONCURRENT=100,\n",
    "            TIMEOUT=8,\n",
    "            post_process=save_df,\n",
    "            DATAPATH=DATAPATH,\n",
    "            OP_FILENAME='df_opt_prices.pkl'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# . get fresh option margins\n",
    "opt_cos = [(c, o) for c, o in zip(fresh_contracts, fresh_orders)]\n",
    "\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_opt_margins = ib.run(\n",
    "        executeAsync(\n",
    "            ib=ib,\n",
    "            algo=margin,\n",
    "            cts=opt_cos,\n",
    "            CONCURRENT=200,\n",
    "            TIMEOUT=5,\n",
    "            post_process=save_df,\n",
    "            DATAPATH=DATAPATH,\n",
    "            OP_FILENAME='df_opt_margins.pkl'            \n",
    "        )\n",
    "    )\n",
    "\n",
    "opt_pm_time.stop()\n",
    "\n",
    "# * GET ROM AND SET EXPECTED OPTION PRICE\n",
    "\n",
    "# . integrate price, iv and margins\n",
    "df_fresh2 = df_fresh1.set_index('conId')\\\n",
    "                     .join(df_opt_margins.set_index('conId')[['comm', 'margin']])\\\n",
    "                     .join(df_opt_prices .set_index('conId')[['bid', 'ask', 'close', 'last', 'iv', 'price']])\\\n",
    "                     .reset_index()\n",
    "\n",
    "# . update null iv with und_iv\n",
    "m_iv = df_fresh2.iv.isnull()\n",
    "df_fresh2.loc[m_iv, 'iv'] = df_fresh2[m_iv].und_iv\n",
    "\n",
    "# . update calculated sd mult for strike\n",
    "df_fresh2.insert(19, 'sdMult', calcsdmult_df(df_fresh2.strike, df_fresh2))\n",
    "\n",
    "# . compute rom and down-sort on it\n",
    "df_fresh2['rom'] = (df_fresh2.price * df_fresh2.lot - df_fresh2.comm).clip(0) / \\\n",
    "                    df_fresh2.margin * 365 / df_fresh2.dte\n",
    "\n",
    "df_fresh2 = df_fresh2.sort_values('rom', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# .establish expRom\n",
    "#    ... for those whose RoM is < MINROM, make it equal to MINROM\n",
    "df_fresh2['expRom'] = np.maximum(ibp.MINEXPROM, df_fresh2.rom)\n",
    "\n",
    "# . set expPrice to be based on expRom\n",
    "df_fresh2['expPrice'] = (df_fresh2.expRom * np.maximum(ibp.MINOPTSELLPRICE, df_fresh2.price) /\n",
    "                      df_fresh2.rom).apply(lambda x: get_prec(x, ibp.PREC))\n",
    "\n",
    "# * PICKLE AND SAVE TO EXCEL\n",
    "df_fresh2.to_pickle(DATAPATH.joinpath('df_fresh.pkl'))\n",
    "\n",
    "df_calls = df_fresh2[df_fresh2.right == 'C'].reset_index(drop=True)\n",
    "df_puts = df_fresh2[df_fresh2.right == 'P'].reset_index(drop=True)\n",
    "\n",
    "# ... initiate Excel writer object\n",
    "writer = pd.ExcelWriter(\n",
    "    DATAPATH.joinpath('df_fresh.xlsx'), engine='xlsxwriter')\n",
    "\n",
    "df_fresh2.to_excel(\n",
    "    writer, sheet_name='All', float_format='%.2f',\n",
    "    index=False, freeze_panes=(1, 1))\n",
    "\n",
    "df_calls.to_excel(\n",
    "    writer, sheet_name='Calls', float_format='%.2f',\n",
    "    index=False, freeze_panes=(1, 1))\n",
    "\n",
    "df_puts.to_excel(\n",
    "    writer, sheet_name='Puts', float_format='%.2f',\n",
    "    index=False, freeze_panes=(1, 1))\n",
    "\n",
    "all_sheet = writer.sheets['All']\n",
    "puts_sheet = writer.sheets['Calls']\n",
    "calls_sheet = writer.sheets['Puts']\n",
    "sheets = [all_sheet, puts_sheet, calls_sheet]\n",
    "\n",
    "for sht in sheets:\n",
    "    # Hide all rows without data\n",
    "    sht.set_default_row(hide_unused_rows=True)\n",
    "    # Hide conId and contract cols\n",
    "    sht.set_column('A:B', None, None, {'hidden': True})\n",
    "\n",
    "try:\n",
    "    writer.save()\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f'\\nError {e}: propose_nakeds.xlsx is open or has some issues!!!\\n')\n",
    "    \n",
    "fresh_time.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
