{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring exec_pool as a core engine\n",
    "We are refactoring execution of a contract pool by building a new `async exec_pool` function.\n",
    "\n",
    "`async exec_pool`:\n",
    "1. processes sets of contracts to run specific algos \n",
    "2. with controlled concurrency \n",
    "3. with an option to produce df outputs\n",
    "   - which provides the capability to checkpoint to a pickle file...\n",
    "   - ... thereby `re-start` from near a point of failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET = 'NSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import asyncio\n",
    "\n",
    "from ib_insync import IB, util, Option, MarketOrder, Contract\n",
    "from typing import Callable, Coroutine, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** LOCAL IMPORTS\n",
    "from engine import ohlc, chain, qualify, und, Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** JUPYTER SPECIFIC\n",
    "# .... Will be ignored in IDE / command-lines\n",
    "import IPython as ipy\n",
    "if ipy.get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    util.startLoop()\n",
    "    pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** SET PATHS\n",
    "cwd = pathlib.Path.cwd() # working directory from where python was initiated\n",
    "\n",
    "# ...set up data and log path for local (learn)\n",
    "THIS_FOLDER = '' # ! DUMMY setup for Jupyter. In .py file it is ``os.path.dirname(os.path.abspath(__file__))``\n",
    "LOGPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", \"log\")\n",
    "DATAPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", MARKET.lower())\n",
    "\n",
    "# ...get capability to import programs from `asyncib` folder\n",
    "IBPATH = cwd.parent.parent.joinpath('asyncib') # where ib programs are stored\n",
    "if str(IBPATH) not in sys.path:  # Convert it to string!\n",
    "    sys.path.append(str(IBPATH))\n",
    "    \n",
    "IBDATAPATH = IBPATH.joinpath('data', MARKET.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** SET VARIABLES & LOGS\n",
    "ibp = Vars(MARKET.upper())\n",
    "\n",
    "HOST, PORT, CID = ibp.HOST, ibp.PORT, ibp.CID\n",
    "\n",
    "LOGFILE = LOGPATH.joinpath(MARKET.lower() + \"_base.log\")\n",
    "util.logToFile(path=LOGFILE, level=30)\n",
    "with open(LOGFILE, \"w\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ``async exec_pool`` algo\n",
    "### with concurrency control and post-processing checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remains(cts):\n",
    "    \"\"\"Generates tuples for tracking remaining contracts\"\"\"\n",
    "    if isinstance(cts, Contract): # Single contract\n",
    "        remaining = cts, None # Convert to tuple with None\n",
    "        \n",
    "    elif isinstance(cts, pd.Series): # Contracts given as a series\n",
    "        if len(cts) == 1: # Single contract given as a series\n",
    "            remaining = list(cts)[0], None # Convert to a tuple with None\n",
    "        else:\n",
    "            remaining = ((c, None) for c in cts)\n",
    "            \n",
    "    elif isinstance(cts, list): # List of Contracts or (c, o) tuples\n",
    "        if len(cts) == 1: # Single contract or (c, o)\n",
    "            if isinstance(cts[0], tuple): # (c, o) tuple\n",
    "                remaining = tuple(cts[0])\n",
    "            else: # Single contract\n",
    "                remaining = cts[0].iloc[0], None\n",
    "        else: # Multiple contracts or (c, o)\n",
    "            if isinstance(cts[0], tuple): # (c, o) tuples\n",
    "                remaining = tuple((c, o) for c, o in cts)\n",
    "            else: # Multiple contracts\n",
    "                remaining = tuple((c, None) for c in cts)\n",
    "    else:\n",
    "        remaining = None\n",
    "        \n",
    "    return remaining\n",
    "\n",
    "async def executeAsync(ib: IB(),\n",
    "                       algo: Callable[..., Coroutine],  # coro name\n",
    "                       cts: Union[Contract, pd.Series, list, tuple], # list of contracts\n",
    "                       post_process: Callable[[set, pathlib.Path, str], pd.DataFrame]=None, # If checkpoint is needed\n",
    "                       FSPATH: pathlib.Path=None, # Necessary for post_process\n",
    "                       CONCURRENT: int=40, # adjust to prevent overflows\n",
    "                       TIMEOUT: None=None, # if None, no progress messages shown\n",
    "                       OP_FILENAME: str='', # output file name\n",
    "                       **kwargs, # keyword inputs for algo\n",
    "                       ):\n",
    "    \n",
    "    tasks = set()\n",
    "    results = set()\n",
    "    remaining = remains(cts)\n",
    "    \n",
    "    # Determine unique names for tasks\n",
    "    ct_name=\"c[0].symbol+c[0].lastTradeDateOrContractMonth[-4:]+c[0].right+str(c[0].strike)+'..'\"\n",
    "    \n",
    "    \"\"\"try:\n",
    "        remaining[0].symbol\n",
    "        \n",
    "    except AttributeError: # It is a (contract, order) tuple for margin algo!\n",
    "        ct_name=\"c[0].symbol+c[0].lastTradeDateOrContractMonth[-4:]+c[0].right+str(c[0].strike)+'..'\"\n",
    "        \n",
    "    else: # for all algos, except margin algo\n",
    "        ct_name=\"c.symbol+c.lastTradeDateOrContractMonth[-4:]+c.right+str(c.strike)+'..'\"\"\"\n",
    "\n",
    "    # Get the results\n",
    "    while len(remaining):\n",
    "    \n",
    "        # Tasks limited by concurrency\n",
    "        if len(remaining) <= CONCURRENT:\n",
    "            print([c[0].symbol+c[0].lastTradeDateOrContractMonth[-4:]+c[0].right+str(c[0].strike)+'..' for c in remaining]) # !!!TEMPORARY\n",
    "            tasks.update(asyncio.create_task(algo(ib, c, **kwargs), name=eval(ct_name)) for c in remaining)\n",
    "        else:\n",
    "            tasks.update(asyncio.create_task(algo(ib, c, **kwargs), name=eval(ct_name)) for c in remaining[:CONCURRENT])\n",
    "            \n",
    "        print(f\"\\nTasks: {tasks}\\n\") # !!! TEMPORARY\n",
    "\n",
    "        # Execute tasks\n",
    "        while len(tasks):\n",
    "\n",
    "            done, tasks = await asyncio.wait(tasks,\n",
    "                                            timeout=TIMEOUT,\n",
    "                                            return_when=asyncio.ALL_COMPLETED)\n",
    "\n",
    "            # Remove dones from remaining\n",
    "            done_names = [d.get_name() for d in done]\n",
    "            remaining = [c for c in remaining if eval(ct_name) not in done_names]\n",
    "            \n",
    "            # Update results and checkpoint\n",
    "            results.update(done)\n",
    "            \n",
    "            # Checkpoint the results\n",
    "            if post_process:\n",
    "                output = post_process(results, FSPATH, OP_FILENAME)\n",
    "            else:\n",
    "                output = results\n",
    "            \n",
    "            if TIMEOUT:\n",
    "                print(f'\\nCompleted {done_names[:2]} {len(results)} out of {len(cts)} .. remaining {[eval(ct_name) for c in remaining][:2]}')\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def save_df(results: set, FSPATH: pathlib.Path, file_name: str='') -> pd.DataFrame():\n",
    "\n",
    "    \"\"\"if results:\n",
    "        df = pd.concat([r.result() for r in results if r], ignore_index=True)\n",
    "        if file_name:\n",
    "            df.to_pickle(FSPATH.joinpath(file_name))\n",
    "    else:\n",
    "        df = pd.DataFrame([]) # results are not yet ready!\n",
    "    return df\"\"\"\n",
    "    \n",
    "    print(results) #!!! TEMPORARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `async exec_pool` algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get symlots\n",
    "df_symlots = pd.read_pickle(DATAPATH.joinpath('df_symlots.pkl'))\n",
    "\n",
    "und_cts = df_symlots.contract.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Contract(secType='IND', conId=56994300, symbol='BANKNIFTY', exchange='NSE', currency='INR', localSymbol='BANKNIFTY'),\n",
       " Contract(secType='IND', conId=51497778, symbol='NIFTY50', exchange='NSE', currency='INR', localSymbol='NIFTY50'),\n",
       " Contract(secType='STK', conId=64769335, symbol='BHARTIART', exchange='NSE', primaryExchange='NSE', currency='INR', localSymbol='BHARTIARTL', tradingClass='BHARTIART'),\n",
       " Contract(secType='STK', conId=56986798, symbol='ADANIENT', exchange='NSE', primaryExchange='NSE', currency='INR', localSymbol='ADANIENT', tradingClass='ADANIENT')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment for !!! DATA LIMITING underlying contracts\n",
    "und_cts = list(und_cts[:4])\n",
    "und_cts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remaining = remains(und_cts)\n",
    "remaining\n",
    "\n",
    "[c[0].symbol+c[0].lastTradeDateOrContractMonth[-4:]+c[0].right+str(c[0].strike) for c in remaining]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the OHLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BANKNIFTY0.0..', 'NIFTY500.0..', 'BHARTIART0.0..', 'ADANIENT0.0..']\n",
      "\n",
      "Tasks: {<Task pending name='BANKNIFTY0.0..' coro=<ohlc() running at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197>>, <Task pending name='BHARTIART0.0..' coro=<ohlc() running at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197>>, <Task pending name='NIFTY500.0..' coro=<ohlc() running at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197>>, <Task pending name='ADANIENT0.0..' coro=<ohlc() running at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197>>}\n",
      "\n",
      "{<Task finished name='BANKNIFTY0.0..' coro=<ohlc() done, defined at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197> exception=AttributeError(\"'tuple' object has no attribute 'includeExpired'\")>, <Task finished name='BHARTIART0.0..' coro=<ohlc() done, defined at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197> exception=AttributeError(\"'tuple' object has no attribute 'includeExpired'\")>, <Task finished name='NIFTY500.0..' coro=<ohlc() done, defined at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197> exception=AttributeError(\"'tuple' object has no attribute 'includeExpired'\")>, <Task finished name='ADANIENT0.0..' coro=<ohlc() done, defined at C:\\Users\\User\\Documents\\Business\\Projects\\learn\\ib\\engine.py:197> exception=AttributeError(\"'tuple' object has no attribute 'includeExpired'\")>}\n",
      "\n",
      "Completed ['BANKNIFTY0.0..', 'BHARTIART0.0..'] 4 out of 4 .. remaining []\n",
      "Wall time: 98.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    \n",
    "    # Get the underlyings\n",
    "    df_ohlcs = ib.run(executeAsync(ib=ib, algo=ohlc, cts=und_cts, \n",
    "                                  CONCURRENT=20, TIMEOUT=10.0, \n",
    "                                  post_process=save_df, FSPATH=DATAPATH, OP_FILENAME='',\n",
    "                                  **{'DURATION': 365, 'OHLC_DELAY': 20},\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100),\n",
       " MarketOrder(action='SELL', totalQuantity=100)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[MarketOrder('SELL', 100)] * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get underlyings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    \n",
    "    # Get the underlyings\n",
    "    df_unds = ib.run(executeAsync(ib=ib, algo=unds, cts=und_cts, \n",
    "                                  CONCURRENT=40, TIMEOUT=2.0, \n",
    "                                  post_process=save_df, FSPATH=DATAPATH, OP_FILENAME='df_unds.pkl',\n",
    "                                  **{'FILL_DELAY': 8},\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make the chains\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_chains = ib.run(executeAsync(ib=ib, algo=chains, cts=und_cts,\n",
    "                                  CONCURRENT=44, TIMEOUT=5,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_chains.pkl',\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualify ready-made options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pd.read_pickle(IBDATAPATH.joinpath('df_qopts.pkl'))\n",
    "opts_cts = [Option(symbol=s, lastTradeDateOrContractMonth=e, \n",
    "                   strike=k, right=r, exchange='SMART', conId='') \n",
    "            for s, e, k, r, cid in zip(opts.symbol, opts.expiry, opts.strike, opts.right, range(1, len(opts)))]\n",
    "len(opts_cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_qopts = ib.run(executeAsync(ib=ib, algo=qualify, cts=opts_cts, \n",
    "                                  CONCURRENT=200, TIMEOUT=2.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and qualify fresh set of options (MEGA)\n",
    "* Run this code if the ENTIRE set of options available in the market for ALL options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us pick assemble the contracts to get our qualifications\n",
    "\n",
    "# Build the option contracts\n",
    "\n",
    "puts = [Option(s, e, k, 'P', 'SMART')\n",
    "        for s, e, k\n",
    "        in zip(df_chains.symbol, df_chains.expiry, df_chains.strike)]\n",
    "\n",
    "calls = [Option(s, e, k, 'C', 'SMART')\n",
    "        for s, e, k\n",
    "        in zip(df_chains.symbol, df_chains.expiry, df_chains.strike)]\n",
    "\n",
    "cts = puts + calls\n",
    "\n",
    "df_cts = util.df(cts).iloc[:, :6].\\\n",
    "            rename(columns={'lastTradeDateOrContractMonth': 'expiry'}).\\\n",
    "                assign(contract=cts)\n",
    "                \n",
    "df_cts.conId = None # Replace `conId` as None to track completeness\n",
    "\n",
    "df_cts = df_cts.sample(len(df_cts)) # !!! TO BE DELETED in live run\n",
    "df_cts = df_cts.reset_index(drop=True) # Index used to track progress\n",
    "\n",
    "# *** Done once only in the TEST ***!!!\n",
    "df_cts.to_pickle(FSPATH.joinpath('all_raw_opts.pkl'))\n",
    "\n",
    "df_cts = pd.read_pickle(FSPATH.joinpath('all_raw_opts.pkl'))\n",
    "\n",
    "s = sorted(df_cts.symbol.unique())\n",
    "print(f\"# of symbols: {len(s)}, # of option contracts: {len(df_cts)}, # no of expiries: {len(df_cts.expiry.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fresh_opts = df_cts.contract.sample(500).to_list() # !!! DATA LIMITER - 500 contracts\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_qopts = ib.run(executeAsync(ib=ib, algo=qualify, cts=fresh_opts, \n",
    "                                  CONCURRENT=200, TIMEOUT=5.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_qualopts1.pkl',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the price of qualified options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_qopts = pd.read_pickle(FSPATH.joinpath('df_qualopts1.pkl'))\n",
    "\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_price = ib.run(executeAsync(ib=ib, algo=prices, cts=df_qopts.contract.to_list(), \n",
    "                                  CONCURRENT=200, TIMEOUT=10.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare cos for margins from qualified options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symlots = pd.read_pickle(IBDATAPATH.joinpath('df_symlots.pkl'))\n",
    "df_raw_opts = pd.read_pickle(IBDATAPATH.joinpath('df_qopts.pkl'))\n",
    "\n",
    "if MARKET == 'NSE':\n",
    "    df_raw_opts['expiryM'] = df_raw_opts.expiry.apply(\n",
    "        lambda d: d[:4] + '-' + d[4:6])\n",
    "    cols1 = ['symbol', 'expiryM']\n",
    "    df_raw_opts = df_raw_opts.set_index(cols1).join(\n",
    "        df_symlots[cols1 + ['lot']].set_index(cols1)).reset_index()\n",
    "    df_raw_opts = df_raw_opts.drop('expiryM', 1)\n",
    "else:\n",
    "    df_raw_opts['lot'] = 100\n",
    "\n",
    "# ... build cos (contract, orders)\n",
    "opts = df_raw_opts.contract.to_list()\n",
    "orders = [MarketOrder('SELL', lot / lot) if MARKET.upper() ==\n",
    "          'SNP' else MarketOrder('SELL', lot) for lot in df_raw_opts.lot]\n",
    "cos = [(c, o) for c, o in zip(opts, orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = cos[:500] # !!! DATA LIMITER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get option margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_margins = ib.run(executeAsync(ib=ib, algo=margins, cts=cos, \n",
    "                                  CONCURRENT=200, TIMEOUT=5.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_margins.pkl',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get option prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_price = ib.run(executeAsync(ib=ib, algo=prices, cts=opts, \n",
    "                                  CONCURRENT=200, TIMEOUT=10.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_optprices.pkl',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_price[~df_price.price.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index('conId').join(df_margins[['conId', 'margin', 'lot', 'comm']].set_index('conId')).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
