{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring exec_pool as a core engine\n",
    "We are refactoring execution of a contract pool by building a new `async exec_pool` function.\n",
    "\n",
    "`async exec_pool`:\n",
    "1. processes sets of contracts to run specific algos \n",
    "2. with controlled concurrency \n",
    "3. with an option to produce df outputs\n",
    "   - which provides the capability to checkpoint to a pickle file...\n",
    "   - ... thereby `re-start` from near a point of failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET = 'NSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import asyncio\n",
    "\n",
    "from ib_insync import IB, util, Option, MarketOrder, Contract\n",
    "from typing import Callable, Coroutine, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** LOCAL IMPORTS\n",
    "from engine import ohlc, chain, qualify, und, Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** JUPYTER SPECIFIC\n",
    "# .... Will be ignored in IDE / command-lines\n",
    "import IPython as ipy\n",
    "if ipy.get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    util.startLoop()\n",
    "    pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** SET PATHS\n",
    "cwd = pathlib.Path.cwd() # working directory from where python was initiated\n",
    "\n",
    "# ...set up data and log path for local (learn)\n",
    "THIS_FOLDER = '' # ! DUMMY setup for Jupyter. In .py file it is ``os.path.dirname(os.path.abspath(__file__))``\n",
    "LOGPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", \"log\")\n",
    "DATAPATH = pathlib.Path.cwd().joinpath(THIS_FOLDER, \"data\", MARKET.lower())\n",
    "\n",
    "# ...get capability to import programs from `asyncib` folder\n",
    "IBPATH = cwd.parent.parent.joinpath('asyncib') # where ib programs are stored\n",
    "if str(IBPATH) not in sys.path:  # Convert it to string!\n",
    "    sys.path.append(str(IBPATH))\n",
    "    \n",
    "IBDATAPATH = IBPATH.joinpath('data', MARKET.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** SET VARIABLES & LOGS\n",
    "ibp = Vars(MARKET.upper())\n",
    "\n",
    "HOST, PORT, CID = ibp.HOST, ibp.PORT, ibp.CID\n",
    "\n",
    "LOGFILE = LOGPATH.joinpath(MARKET.lower() + \"_base.log\")\n",
    "util.logToFile(path=LOGFILE, level=30)\n",
    "with open(LOGFILE, \"w\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ``async exec_pool`` algo\n",
    "### with concurrency control and post-processing checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** EXECUTION\n",
    "\n",
    "# .make name for symbol being processed by the engine\n",
    "def make_name(cts):\n",
    "    \"\"\"Generates name for contract(s)\"\"\"\n",
    "    try:\n",
    "        output = [c.symbol + c.lastTradeDateOrContractMonth[-4:] +\n",
    "                  c.right + str(c.strike) + '..' for c in cts]\n",
    "\n",
    "    except TypeError as te:  # single non-iterable element\n",
    "        if cts:  # not empty!\n",
    "            output = cts.symbol + cts.lastTradeDateOrContractMonth[-4:] + \\\n",
    "                cts.right + str(cts.strike)\n",
    "        else:\n",
    "            output = cts\n",
    "\n",
    "    except AttributeError as ae1:  # multiple (p, s) combination\n",
    "        try:\n",
    "            output = [c[0].symbol + c[0].lastTradeDateOrContractMonth[-4:] +\n",
    "                      c[0].right + str(c[0].strike) + '..' for c in cts]\n",
    "        except TypeError as ae2:\n",
    "            output = cts[0].symbol + cts[0].lastTradeDateOrContractMonth[-4:] +\\\n",
    "                cts[0].right + str(cts[0].strike)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .the core engine\n",
    "async def executeAsync(\n",
    "    ib: IB(),\n",
    "    algo: Callable[..., Coroutine],  # coro name\n",
    "    cts: Union[Contract, pd.Series, list, tuple],  # list of contracts\n",
    "    post_process: Callable[\n",
    "        [set, pathlib.Path, str], pd.DataFrame\n",
    "    ] = None,  # If checkpoint is needed\n",
    "    DATAPATH: pathlib.Path = None,  # Necessary for post_process\n",
    "    CONCURRENT: int = 40,  # adjust to prevent overflows\n",
    "    TIMEOUT: None = None,  # if None, no progress messages shown\n",
    "    OP_FILENAME: str = \"\",  # output file name\n",
    "    **kwargs,  # keyword inputs for algo\n",
    "):\n",
    "\n",
    "    tasks = set()\n",
    "    results = set()\n",
    "    remaining = pre_process(cts)\n",
    "    last_len_tasks = 0  # tracking last length for error catch\n",
    "\n",
    "    # Get the results\n",
    "    while len(remaining):\n",
    "\n",
    "        # Tasks limited by concurrency\n",
    "        if len(remaining) <= CONCURRENT:\n",
    "\n",
    "            tasks.update(\n",
    "                asyncio.create_task(\n",
    "                    algo(ib, c, **kwargs), name=make_name(c))\n",
    "                for c in remaining\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            tasks.update(\n",
    "                asyncio.create_task(algo(ib, c, **kwargs), name=make_name(c))\n",
    "                for c in remaining[:CONCURRENT]\n",
    "            )\n",
    "\n",
    "        # Execute tasks\n",
    "        while len(tasks):\n",
    "\n",
    "            done, tasks = await asyncio.wait(\n",
    "                tasks, timeout=TIMEOUT, return_when=asyncio.ALL_COMPLETED\n",
    "            )\n",
    "\n",
    "            # Remove dones from remaining\n",
    "            done_names = [d.get_name() for d in done]\n",
    "            remaining = [c for c in remaining if make_name(\n",
    "                c) not in done_names]\n",
    "\n",
    "            # Update results and checkpoint\n",
    "            results.update(done)\n",
    "\n",
    "            # Checkpoint the results\n",
    "            if post_process:\n",
    "                output = post_process(results, DATAPATH, OP_FILENAME)\n",
    "            else:\n",
    "                output = results\n",
    "\n",
    "            if TIMEOUT:\n",
    "                if remaining:\n",
    "                    print(\n",
    "                        f\"\\nDone {algo.__name__} for {done_names[:2]} {len(results)} out of {len(cts)}. Pending {[make_name(c) for c in remaining][:2]}\"\n",
    "                    )\n",
    "\n",
    "                # something wrong. Task is not progressing\n",
    "                if (len(tasks) == last_len_tasks) & (len(tasks) > 0):\n",
    "                    print(\n",
    "                        f\"\\n @ ALERT @: Tasks are not progressing. Pending tasks will be killed in 5 seconds !\\n\"\n",
    "                    )\n",
    "                    dn, pend = await asyncio.wait(tasks, timeout=5.0)\n",
    "                    if len(dn) > 0:\n",
    "                        results.update(dn)\n",
    "\n",
    "                    tasks.difference_update(dn)\n",
    "                    tasks.difference_update(pend)\n",
    "\n",
    "                    pend_names = [p.get_name() for p in pend]\n",
    "                    # remove pending from remaining\n",
    "                    remaining = [c for c in remaining\n",
    "                                 if make_name(c) not in pend_names]\n",
    "\n",
    "                # re-initialize last length of tasks\n",
    "                last_len_tasks = len(tasks)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def save_df(results: set, DATAPATH: pathlib.Path, file_name: str = \"\") -> pd.DataFrame():\n",
    "\n",
    "    if results:\n",
    "        df = pd.concat([r.result() for r in results if r], ignore_index=True)\n",
    "        if file_name:\n",
    "            df.to_pickle(DATAPATH.joinpath(file_name))\n",
    "    else:\n",
    "        df = pd.DataFrame([])  # results are not yet ready!\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .preprocessing data for the core engine\n",
    "def pre_process(cts):\n",
    "    \"\"\"Generates tuples for input to the engine\"\"\"\n",
    "\n",
    "    try:\n",
    "        symbol = cts.symbol\n",
    "        output = (cts, None),\n",
    "    \n",
    "    except AttributeError as ae1: # it's an iterable!\n",
    "        try:\n",
    "            symbols = [c.symbol for c in cts]\n",
    "            \n",
    "            if len(symbols) == 1:\n",
    "                output = (cts[0], None),\n",
    "            else:\n",
    "                output = ((c, None) for c in cts)\n",
    "            \n",
    "        except AttributeError as ae2: # 2nd value is MarketOrder!\n",
    "            try:\n",
    "                output = tuple(cts)\n",
    "            except:\n",
    "                print(f'Unknown error in {ae2}')\n",
    "                output = None\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing pre_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = []\n",
    "cts = Contract(conId=1234)\n",
    "cts = Contract(conId=1234), MarketOrder('SELL', 3)\n",
    "cts = [Contract(conId=1234)]\n",
    "cts = [Contract(conId=1234), Contract(conId=3456)]\n",
    "cts = [(Contract(conId=1234), MarketOrder('SELL', 3))]\n",
    "cts = [(Contract(conId=1234), MarketOrder('SELL', 3)), (Contract(conId=3456), MarketOrder('SELL', 3))]\n",
    "cts = [Contract(conId=1234), MarketOrder('SELL', 3)]\n",
    "cts = Contract(conId=1234), Contract(conId=3456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Contract(conId=1234), None), (Contract(conId=3456), None)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pre_process(cts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `async exec_pool` algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get symlots\n",
    "df_symlots = pd.read_pickle(DATAPATH.joinpath('df_symlots.pkl'))\n",
    "\n",
    "und_cts = df_symlots.contract.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for !!! DATA LIMITING underlying contracts\n",
    "und_cts = list(und_cts[:4])\n",
    "und_cts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remaining = remains(und_cts)\n",
    "remaining\n",
    "\n",
    "[c[0].symbol+c[0].lastTradeDateOrContractMonth[-4:]+c[0].right+str(c[0].strike) for c in remaining]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the OHLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    \n",
    "    # Get the underlyings\n",
    "    df_ohlcs = ib.run(executeAsync(ib=ib, algo=ohlc, cts=und_cts, \n",
    "                                  CONCURRENT=20, TIMEOUT=10.0, \n",
    "                                  post_process=save_df, FSPATH=DATAPATH, OP_FILENAME='',\n",
    "                                  **{'DURATION': 365, 'OHLC_DELAY': 20},\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[MarketOrder('SELL', 100)] * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get underlyings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    \n",
    "    # Get the underlyings\n",
    "    df_unds = ib.run(executeAsync(ib=ib, algo=unds, cts=und_cts, \n",
    "                                  CONCURRENT=40, TIMEOUT=2.0, \n",
    "                                  post_process=save_df, FSPATH=DATAPATH, OP_FILENAME='df_unds.pkl',\n",
    "                                  **{'FILL_DELAY': 8},\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make the chains\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_chains = ib.run(executeAsync(ib=ib, algo=chains, cts=und_cts,\n",
    "                                  CONCURRENT=44, TIMEOUT=5,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_chains.pkl',\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualify ready-made options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pd.read_pickle(IBDATAPATH.joinpath('df_qopts.pkl'))\n",
    "opts_cts = [Option(symbol=s, lastTradeDateOrContractMonth=e, \n",
    "                   strike=k, right=r, exchange='SMART', conId='') \n",
    "            for s, e, k, r, cid in zip(opts.symbol, opts.expiry, opts.strike, opts.right, range(1, len(opts)))]\n",
    "len(opts_cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_qopts = ib.run(executeAsync(ib=ib, algo=qualify, cts=opts_cts, \n",
    "                                  CONCURRENT=200, TIMEOUT=2.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and qualify fresh set of options (MEGA)\n",
    "* Run this code if the ENTIRE set of options available in the market for ALL options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us pick assemble the contracts to get our qualifications\n",
    "\n",
    "# Build the option contracts\n",
    "\n",
    "puts = [Option(s, e, k, 'P', 'SMART')\n",
    "        for s, e, k\n",
    "        in zip(df_chains.symbol, df_chains.expiry, df_chains.strike)]\n",
    "\n",
    "calls = [Option(s, e, k, 'C', 'SMART')\n",
    "        for s, e, k\n",
    "        in zip(df_chains.symbol, df_chains.expiry, df_chains.strike)]\n",
    "\n",
    "cts = puts + calls\n",
    "\n",
    "df_cts = util.df(cts).iloc[:, :6].\\\n",
    "            rename(columns={'lastTradeDateOrContractMonth': 'expiry'}).\\\n",
    "                assign(contract=cts)\n",
    "                \n",
    "df_cts.conId = None # Replace `conId` as None to track completeness\n",
    "\n",
    "df_cts = df_cts.sample(len(df_cts)) # !!! TO BE DELETED in live run\n",
    "df_cts = df_cts.reset_index(drop=True) # Index used to track progress\n",
    "\n",
    "# *** Done once only in the TEST ***!!!\n",
    "df_cts.to_pickle(FSPATH.joinpath('all_raw_opts.pkl'))\n",
    "\n",
    "df_cts = pd.read_pickle(FSPATH.joinpath('all_raw_opts.pkl'))\n",
    "\n",
    "s = sorted(df_cts.symbol.unique())\n",
    "print(f\"# of symbols: {len(s)}, # of option contracts: {len(df_cts)}, # no of expiries: {len(df_cts.expiry.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fresh_opts = df_cts.contract.sample(500).to_list() # !!! DATA LIMITER - 500 contracts\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_qopts = ib.run(executeAsync(ib=ib, algo=qualify, cts=fresh_opts, \n",
    "                                  CONCURRENT=200, TIMEOUT=5.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_qualopts1.pkl',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the price of qualified options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_qopts = pd.read_pickle(FSPATH.joinpath('df_qualopts1.pkl'))\n",
    "\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_price = ib.run(executeAsync(ib=ib, algo=prices, cts=df_qopts.contract.to_list(), \n",
    "                                  CONCURRENT=200, TIMEOUT=10.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare cos for margins from qualified options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symlots = pd.read_pickle(IBDATAPATH.joinpath('df_symlots.pkl'))\n",
    "df_raw_opts = pd.read_pickle(IBDATAPATH.joinpath('df_qopts.pkl'))\n",
    "\n",
    "if MARKET == 'NSE':\n",
    "    df_raw_opts['expiryM'] = df_raw_opts.expiry.apply(\n",
    "        lambda d: d[:4] + '-' + d[4:6])\n",
    "    cols1 = ['symbol', 'expiryM']\n",
    "    df_raw_opts = df_raw_opts.set_index(cols1).join(\n",
    "        df_symlots[cols1 + ['lot']].set_index(cols1)).reset_index()\n",
    "    df_raw_opts = df_raw_opts.drop('expiryM', 1)\n",
    "else:\n",
    "    df_raw_opts['lot'] = 100\n",
    "\n",
    "# ... build cos (contract, orders)\n",
    "opts = df_raw_opts.contract.to_list()\n",
    "orders = [MarketOrder('SELL', lot / lot) if MARKET.upper() ==\n",
    "          'SNP' else MarketOrder('SELL', lot) for lot in df_raw_opts.lot]\n",
    "cos = [(c, o) for c, o in zip(opts, orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = cos[:500] # !!! DATA LIMITER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get option margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_margins = ib.run(executeAsync(ib=ib, algo=margins, cts=cos, \n",
    "                                  CONCURRENT=200, TIMEOUT=5.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_margins.pkl',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get option prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    df_price = ib.run(executeAsync(ib=ib, algo=prices, cts=opts, \n",
    "                                  CONCURRENT=200, TIMEOUT=10.0,\n",
    "                                  post_process=save_df, FSPATH=FSPATH, OP_FILENAME='df_optprices.pkl',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_price[~df_price.price.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index('conId').join(df_margins[['conId', 'margin', 'lot', 'comm']].set_index('conId')).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
