{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET = 'NSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import asyncio\n",
    "\n",
    "from ib_insync import IB, util, Option, MarketOrder, Contract\n",
    "from typing import Callable, Coroutine, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific to Jupyter. Will be ignored in IDE / command-lines\n",
    "import IPython as ipy\n",
    "if ipy.get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    util.startLoop()\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.float_format = '{:,.2f}'.format # set float precision with comma\n",
    "    \n",
    "    THIS_FOLDER = '' # Dummy for jupyter notebook's current folder\n",
    "    BAR_FORMAT = \"{l_bar}{bar:-20}{r_bar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get capability to import programs from `asyncib` folder\n",
    "cwd = pathlib.Path.cwd() # working directory from where python was initiated\n",
    "DATAPATH = cwd.joinpath('data', MARKET.lower()) # path to store data files\n",
    "LOGFILE = cwd.joinpath(THIS_FOLDER, 'data', 'log', 'temp.log') # path to store log files\n",
    "\n",
    "IBPATH = cwd.parent.parent.joinpath('asyncib') # where ib programs are stored\n",
    "\n",
    "# append IBPATH to import programs.\n",
    "if str(IBPATH) not in sys.path:  # Convert it to string!\n",
    "    sys.path.append(str(IBPATH))\n",
    "    \n",
    "IBDATAPATH = IBPATH.joinpath('data', MARKET.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the host, port, cid\n",
    "from engine import Vars\n",
    "\n",
    "ibp = Vars(MARKET.upper())  # IB Parameters from var.yml\n",
    "HOST, PORT, CID = ibp.HOST, ibp.PORT, ibp.CID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pickle files\n",
    "from os import listdir\n",
    "fs = listdir(DATAPATH)\n",
    "\n",
    "files = [f for f in fs if f[-4:] == '.pkl']\n",
    "for f in files:\n",
    "    exec(f\"{f.split('.')[0]} = pd.read_pickle(DATAPATH.joinpath(f))\")\n",
    "np.sort(np.array(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The core engine with pre and post processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** EXECUTION\n",
    "# * Core engine that processes functions and delivers results\n",
    "\n",
    "# .preprocessing data for the core engine\n",
    "\n",
    "\n",
    "def pre_process(cts):\n",
    "    \"\"\"Generates tuples for input to the engine\"\"\"\n",
    "\n",
    "    try:\n",
    "        symbol = cts.symbol\n",
    "        output = ((cts, None),)\n",
    "\n",
    "    except AttributeError as ae1:  # it's an iterable!\n",
    "        try:\n",
    "            symbols = [c.symbol for c in cts]\n",
    "\n",
    "            if len(symbols) == 1:\n",
    "                output = ((cts[0], None),)\n",
    "            else:\n",
    "                output = ((c, None) for c in cts)\n",
    "\n",
    "        except AttributeError as ae2:  # 2nd value is MarketOrder!\n",
    "            try:\n",
    "                output = tuple(cts)\n",
    "            except:\n",
    "                print(f\"Unknown error in {ae2}\")\n",
    "                output = None\n",
    "\n",
    "    return tuple(output)\n",
    "\n",
    "\n",
    "# .make name for symbol being processed by the engine\n",
    "def make_name(cts):\n",
    "    \"\"\"Generates name for contract(s)\"\"\"\n",
    "    try:\n",
    "        output = [\n",
    "            c.symbol\n",
    "            + c.lastTradeDateOrContractMonth[-4:]\n",
    "            + c.right\n",
    "            + str(c.strike)\n",
    "            + \"..\"\n",
    "            for c in cts\n",
    "        ]\n",
    "\n",
    "    except TypeError as te:  # single non-iterable element\n",
    "        if cts != \"\":  # not empty!\n",
    "            output = (\n",
    "                cts.symbol\n",
    "                + cts.lastTradeDateOrContractMonth[-4:]\n",
    "                + cts.right\n",
    "                + str(cts.strike)\n",
    "            )\n",
    "        else:\n",
    "            output = cts\n",
    "\n",
    "    except AttributeError as ae1:  # multiple (p, s) combination\n",
    "        try:\n",
    "            output = [\n",
    "                c[0].symbol\n",
    "                + c[0].lastTradeDateOrContractMonth[-4:]\n",
    "                + c[0].right\n",
    "                + str(c[0].strike)\n",
    "                + \"..\"\n",
    "                for c in cts\n",
    "            ]\n",
    "        except TypeError as te2:\n",
    "            output = (\n",
    "                cts[0].symbol\n",
    "                + cts[0].lastTradeDateOrContractMonth[-4:]\n",
    "                + cts[0].right\n",
    "                + str(cts[0].strike)\n",
    "            )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# .the core engine\n",
    "async def executeAsync(\n",
    "    ib: IB(),\n",
    "    algo: Callable[..., Coroutine],  # coro name\n",
    "    cts: Union[Contract, pd.Series, list, tuple],  # list of contracts\n",
    "    CONCURRENT: int = 44,  # to prevent overflows put 44 * (TIMEOUT-1)\n",
    "    TIMEOUT: None = None,  # if None, no progress messages shown\n",
    "    post_process: Callable[\n",
    "        [set, pathlib.Path, str], pd.DataFrame\n",
    "    ] = None,  # If checkpoint is needed\n",
    "    DATAPATH: pathlib.Path = None,  # Necessary for post_process\n",
    "    OP_FILENAME: str = \"\",  # output file name\n",
    "    SHOW_TQDM: bool = True,  # Show tqdm bar instead of individual messages\n",
    "    REUSE: bool = False,  # Reuse the OP_FILENAME supplied\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    tasks = set()\n",
    "    results = set()\n",
    "    remaining = pre_process(cts)\n",
    "    last_len_tasks = 0  # tracking last length for error catch\n",
    "\n",
    "    # Set pbar\n",
    "    if SHOW_TQDM:\n",
    "        pbar = tqdm(\n",
    "            total=len(remaining),\n",
    "            desc=f\"{algo.__name__}: \",\n",
    "            bar_format=BAR_FORMAT,\n",
    "            ncols=80,\n",
    "            leave=False,\n",
    "        )\n",
    "\n",
    "    # Get the results\n",
    "    while len(remaining):\n",
    "\n",
    "        # Tasks limited by concurrency\n",
    "        if len(remaining) <= CONCURRENT:\n",
    "\n",
    "            tasks.update(\n",
    "                asyncio.create_task(algo(ib, c, **kwargs), name=make_name(c))\n",
    "                for c in remaining\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            tasks.update(\n",
    "                asyncio.create_task(algo(ib, c, **kwargs), name=make_name(c))\n",
    "                for c in remaining[:CONCURRENT]\n",
    "            )\n",
    "\n",
    "        # Execute tasks\n",
    "        while len(tasks):\n",
    "\n",
    "            done, tasks = await asyncio.wait(\n",
    "                tasks, timeout=TIMEOUT, return_when=asyncio.ALL_COMPLETED\n",
    "            )\n",
    "\n",
    "            # Remove dones from remaining\n",
    "            done_names = [d.get_name() for d in done]\n",
    "            remaining = [c for c in remaining if make_name(c) not in done_names]\n",
    "\n",
    "            # Update results and checkpoint\n",
    "            results.update(done)\n",
    "\n",
    "            # Checkpoint the results\n",
    "            if post_process:\n",
    "\n",
    "                output = post_process(\n",
    "                    results=results,\n",
    "                    DATAPATH=DATAPATH,\n",
    "                    REUSE=REUSE,\n",
    "                    LAST_RUN=False,\n",
    "                    OP_FILENAME=OP_FILENAME,\n",
    "                )\n",
    "\n",
    "                if not output.empty:\n",
    "                    REUSE = False  # for second run onwards\n",
    "\n",
    "            else:\n",
    "                output = results\n",
    "\n",
    "            if TIMEOUT:\n",
    "\n",
    "                if remaining:\n",
    "\n",
    "                    if SHOW_TQDM:\n",
    "                        pbar.update(len(done))\n",
    "\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"\\nDone {algo.__name__} for {done_names[:2]} {len(results)} out of {len(cts)}. Pending {[make_name(c) for c in remaining][:2]}\"\n",
    "                        )\n",
    "\n",
    "                # something wrong. Task is not progressing\n",
    "                if (len(tasks) == last_len_tasks) & (len(tasks) > 0):\n",
    "                    print(\n",
    "                        f\"\\n @ ALERT @: Tasks are failing !\\n\"+ \\\n",
    "                        f\"Pending {len(tasks)} \" + \\\n",
    "                        f\"tasks such as {[t.get_name() for t in tasks][:3]}\\n\" +\\\n",
    "                        f\"... will be killed in 5 seconds\\n\"\n",
    "                    )\n",
    "                    dn, pend = await asyncio.wait(tasks, timeout=5.0)\n",
    "                    if len(dn) > 0:\n",
    "                        results.update(dn)\n",
    "\n",
    "                    tasks.difference_update(dn)\n",
    "                    tasks.difference_update(pend)\n",
    "\n",
    "                    pend_names = [p.get_name() for p in pend]\n",
    "                    # remove pending from remaining\n",
    "                    remaining = [c for c in remaining if make_name(c) not in pend_names]\n",
    "\n",
    "                # re-initialize last length of tasks\n",
    "                last_len_tasks = len(tasks)\n",
    "\n",
    "    # Make the final output, based on REUSE status\n",
    "\n",
    "    if OP_FILENAME:\n",
    "        df = post_process(\n",
    "            results=set(),  # Empty dataset\n",
    "            DATAPATH=DATAPATH,\n",
    "            REUSE=REUSE,\n",
    "            LAST_RUN=True,\n",
    "            OP_FILENAME=OP_FILENAME,\n",
    "        )\n",
    "    else:\n",
    "        df = output\n",
    "\n",
    "    if SHOW_TQDM:\n",
    "\n",
    "        pbar.update(len(done))\n",
    "        pbar.refresh()\n",
    "        pbar.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# .Process output into dataframes\n",
    "def post_df(\n",
    "    results: set,\n",
    "    DATAPATH: pathlib.Path,\n",
    "    REUSE: bool,\n",
    "    LAST_RUN: bool,\n",
    "    OP_FILENAME: str = \"\",\n",
    ") -> pd.DataFrame():\n",
    "\n",
    "    if results:\n",
    "        df = pd.concat([r.result() for r in results if r], ignore_index=True)\n",
    "\n",
    "        if OP_FILENAME:\n",
    "\n",
    "            if REUSE:\n",
    "\n",
    "                # load the existing file\n",
    "\n",
    "                try:\n",
    "                    df_old = pd.read_pickle(DATAPATH.joinpath(OP_FILENAME))\n",
    "\n",
    "                    # Save old temporarily\n",
    "                    df_old.to_pickle(DATAPATH.joinpath(\"z_temp_\" + OP_FILENAME))\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "\n",
    "            df.to_pickle(DATAPATH.joinpath(OP_FILENAME))\n",
    "\n",
    "    else:\n",
    "\n",
    "        if LAST_RUN:  # Merge new and old df (if available)\n",
    "\n",
    "            if OP_FILENAME:\n",
    "\n",
    "                try:\n",
    "                    df_old = pd.read_pickle(DATAPATH.joinpath(\"z_temp_\" + OP_FILENAME))\n",
    "                    # cleanup temp file\n",
    "                    os.remove(DATAPATH.joinpath(\"z_temp_\" + OP_FILENAME))\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    df_old = pd.DataFrame([])\n",
    "\n",
    "                df_new = pd.read_pickle(DATAPATH.joinpath(OP_FILENAME))\n",
    "                df = df_new.append(df_old).reset_index(drop=True)\n",
    "                df.to_pickle(DATAPATH.joinpath(OP_FILENAME))\n",
    "\n",
    "        else:\n",
    "            df = pd.DataFrame([])  # results are not yet ready!\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick price algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def quick_price(ib: IB, contract: Contract) -> pd.DataFrame:\n",
    "    \n",
    "    if isinstance(contract, tuple):\n",
    "        contract = contract[0]\n",
    "\n",
    "    result = defaultdict(dict)\n",
    "\n",
    "    ticks = ib.reqHistoricalTicks(\n",
    "            contract=contract,\n",
    "            startDateTime=\"\",\n",
    "            endDateTime=datetime.datetime.now(),\n",
    "            numberOfTicks=1,\n",
    "            whatToShow=\"Bid_Ask\",\n",
    "            useRth=False,\n",
    "            ignoreSize=False,\n",
    "        )\n",
    "    \n",
    "    await asyncio.sleep(1) # to make this asyncio friendly!\n",
    "\n",
    "    # extract bid and ask price\n",
    "    try:\n",
    "        bid_ask = ticks[-1]  # bid ask is not availble for Index securities!\n",
    "        result[\"bid\"] = bid_ask.priceBid\n",
    "        result[\"ask\"] = bid_ask.priceAsk\n",
    "\n",
    "    except IndexError:\n",
    "        print(\n",
    "            f\"\\nNo bid-ask for {contract.localSymbol} of secType: {contract.secType}\\n\"\n",
    "        )\n",
    "        result[\"bid\"] = np.nan\n",
    "        result[\"ask\"] = np.nan\n",
    "        \n",
    "    ticks = ib.reqHistoricalTicks(\n",
    "            contract=contract,\n",
    "            startDateTime=\"\",\n",
    "            endDateTime=datetime.datetime.now(),\n",
    "            numberOfTicks=1,\n",
    "            whatToShow=\"Trades\",\n",
    "            useRth=False,\n",
    "            ignoreSize=False,\n",
    "        )\n",
    "    \n",
    "    await asyncio.sleep(1) # to make this asyncio friendly!\n",
    "\n",
    "    # extract last reported price\n",
    "    try:\n",
    "        # pick reported price if available\n",
    "        result[\"last\"] = [t.price for t in ticks if not t.tickAttribLast.unreported][\n",
    "            -1\n",
    "        ]\n",
    "    except IndexError:\n",
    "        # pick up last tick price\n",
    "        try:\n",
    "            result[\"last\"] = ticks[-1].price\n",
    "        except IndexError:\n",
    "            result[\"last\"] = np.nan\n",
    "\n",
    "    # . build the df\n",
    "    df_pr = pd.DataFrame(\n",
    "        [\n",
    "            pd.Series(contract.conId, name=\"conId\"),\n",
    "            pd.Series(contract.symbol, name=\"symbol\"),\n",
    "            pd.Series(contract.localSymbol, name=\"localSymbol\"),\n",
    "            pd.Series(result[\"bid\"], name=\"bid\", dtype=\"float64\"),\n",
    "            pd.Series(result[\"ask\"], name=\"ask\", dtype=\"float64\"),\n",
    "            pd.Series(result[\"last\"], name=\"last\", dtype=\"float64\"),\n",
    "        ]\n",
    "    ).T\n",
    "\n",
    "    # . use bid-ask avg if last price is not available\n",
    "    df_pr = df_pr.assign(\n",
    "        price=df_pr[\"last\"].combine_first(df_pr[[\"bid\", \"ask\"]].mean(axis=1))\n",
    "    )\n",
    "\n",
    "    return df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def quick_price_async(ib: IB, contract: Contract) -> pd.DataFrame:\n",
    "    \n",
    "    if isinstance(contract, tuple):\n",
    "        contract = contract[0]\n",
    "    \n",
    "    result = defaultdict(dict)\n",
    "    \n",
    "    ticks = await asyncio.gather(ib.reqHistoricalTicksAsync(\n",
    "                                    contract=contract,\n",
    "                                    startDateTime='',\n",
    "                                    endDateTime=datetime.datetime.now(),\n",
    "                                    numberOfTicks=1,\n",
    "                                    whatToShow='Bid_Ask',\n",
    "                                    useRth=False,\n",
    "                                    ignoreSize=False),\n",
    "                                ib.reqHistoricalTicksAsync(\n",
    "                                    contract=contract,\n",
    "                                    startDateTime='',\n",
    "                                    endDateTime=datetime.datetime.now(),\n",
    "                                    numberOfTicks=1,\n",
    "                                    whatToShow='Trades',\n",
    "                                    useRth=False,\n",
    "                                    ignoreSize=False))\n",
    "    \n",
    "    # extract bid and ask price\n",
    "    try:\n",
    "        bid_ask = ticks[0][-1] # bid ask is not availble for Index securities!\n",
    "        result['bid'] = bid_ask.priceBid\n",
    "        result['ask'] = bid_ask.priceAsk\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f'\\nNo bid-ask for {contract.localSymbol} of secType: {contract.secType}')\n",
    "        result['bid'] = np.nan\n",
    "        result['ask'] = np.nan       \n",
    "\n",
    "    # extract last reported price\n",
    "    try:\n",
    "        # pick reported price if available\n",
    "        result['last'] = [t.price for t in ticks[1] \n",
    "                      if not t.tickAttribLast.unreported][-1]\n",
    "    except IndexError:\n",
    "        # pick up last tick price\n",
    "        \n",
    "        try:\n",
    "            result['last'] = ticks[1][-1].price\n",
    "        except IndexError:\n",
    "            result['last'] = np.nan\n",
    "            \n",
    "    \n",
    "    # . build the df\n",
    "    df_pr = pd.DataFrame([pd.Series(contract.conId, name='conId'),\n",
    "                          pd.Series(contract.symbol, name='symbol'),\n",
    "                          pd.Series(contract.localSymbol, name='localSymbol'),\n",
    "                          pd.Series(result['bid'], name='bid', dtype='float64'), \n",
    "                          pd.Series(result['ask'], name='ask', dtype='float64'), \n",
    "                          pd.Series(result['last'], name='last', dtype='float64')]).T\n",
    "\n",
    "    # . use bid-ask avg if last price is not available\n",
    "    df_pr = df_pr.assign(price=df_pr['last'].combine_first(df_pr[['bid', 'ask']].mean(axis=1)))\n",
    "\n",
    "    return df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * IMPORTS\n",
    "import asyncio\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "from io import StringIO\n",
    "from typing import Callable, Coroutine, Union\n",
    "\n",
    "import IPython as ipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from ib_insync import IB, Contract, MarketOrder, Option, util\n",
    "from tqdm import tqdm\n",
    "\n",
    "from support import Timer, Vars, calcsdmult_df, get_dte, get_prob, quick_pf, yes_or_no\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * FUNCTION INPUTS\n",
    "cts = df_unds.contract.unique().tolist() # !!! DATA LIMITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** SETUP\n",
    "THIS_FOLDER = \"\"\n",
    "BAR_FORMAT = \"{desc:<10}{percentage:3.0f}%|{bar:25}{r_bar}{bar:-10b}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with IB().connect(HOST, PORT, CID) as ib:\n",
    "    ib.client.setConnectOptions('PACEAPI')\n",
    "    df = ib.run(executeAsync(\n",
    "        ib = ib,\n",
    "        algo = quick_price,\n",
    "        cts = cts,\n",
    "        CONCURRENT = 40,\n",
    "        TIMEOUT = 5,\n",
    "        SHOW_TQDM = False,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.concat([pd.Series([1, 2, 3], name='numbers'), \n",
    "                 pd.Series(['a', 'b', 'c'], name='letters')], axis=1)\n",
    "df2 = pd.concat([pd.Series([4, 6, 5], name='numbers'), \n",
    "                 pd.Series(['x', 'y', 'z'], name='letters')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-94c1ef1290b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "results = results+tuple([df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results + tuple([df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "      <th>letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numbers letters\n",
       "0        1       a\n",
       "1        2       b\n",
       "2        3       c\n",
       "0        4       x\n",
       "1        6       y\n",
       "2        5       z"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm being pickled\n",
      "I'm being unpickled with these values: {'val': 4}\n"
     ]
    }
   ],
   "source": [
    "class Foo(object):\n",
    "  def __init__(self, val=2):\n",
    "     self.val = val\n",
    "  def __getstate__(self):\n",
    "     print(\"I'm being pickled\")\n",
    "     self.val *= 2\n",
    "     return self.__dict__\n",
    "  def __setstate__(self, d):\n",
    "     print(\"I'm being unpickled with these values: \" + repr(d))\n",
    "     self.__dict__ = d\n",
    "     self.val *= 3\n",
    "\n",
    "import pickle\n",
    "f = Foo()\n",
    "f_data = pickle.dumps(f)\n",
    "f_new = pickle.loads(f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'utcoffset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-332fd7e49777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtzinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcoffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'utcoffset'"
     ]
    }
   ],
   "source": [
    "d.tzinfo.utcoffset(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
