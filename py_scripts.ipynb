{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User integration with Jupyter\n",
    "Ref: [StackOverflow: 31610889](https://stackoverflow.com/questions/31610889/how-to-copy-paste-dataframe-from-stackoverflow-into-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Jupyter output data into a python dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ctrl+C the table output (say 0-3 records of the table above)\n",
    "# Run this...\n",
    "import pandas as pd\n",
    "\n",
    "df_from_pd = pd.read_clipboard()\n",
    "df_from_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Table from Excel via clipboard into a python dictionary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data of interest - with headers - into clipboard with Ctrl+C\n",
    "# Run this...\n",
    "import pandas as pd\n",
    "\n",
    "## Copy the Excel table to the clipboard first.\n",
    "the_dict = pd.read_clipboard().to_dict('records')\n",
    "the_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clipboard from Excel has the following:\n",
    "pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering rows based on conditions from other columns\n",
    "**Ref**: Data School Videos:\n",
    "1. [How do I filter rows of a pandas DataFrame by column value?](https://www.youtube.com/watch?v=2AFGPdNn4FM)\n",
    "2. [How do I apply multiple filter criteria to a pandas DataFrame?](https://www.youtube.com/watch?v=YPItfQ87qjM&t=5s)\n",
    "3. [loc / iloc How do I select multiple rows and columns from a pandas DataFrame?](https://www.youtube.com/watch?v=xvpNA7bC8cs&t=488s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "# Single column condition\n",
    "drinks[drinks[\"continent\"] == 'Asia']\n",
    "\n",
    "# Multiple conditions from a single column\n",
    "drinks[drinks.continent.isin(['Asia', 'Africa'])]   #!!! BE MINDFUL OF TEXT WITH SPACES.\n",
    "\n",
    "### Criteria from multiple columns\n",
    "# Single conditions per column\n",
    "drinks[(drinks[\"continent\"] == 'Asia') & (drinks[\"beer_servings\"] > 100)]\n",
    "\n",
    "# Mix of single and multiple conditions per column\n",
    "# Beer servings > 100 in Asia or Africa, but not in Vietnam\n",
    "drinks[drinks.continent.isin(['Asia', 'Africa']) & (drinks.beer_servings > 100) & ~(drinks.country == 'Vietnam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple sub-string search\n",
    "# Countries in Asia and Africa having the letter 's' or 'w' in them with beer_servings > 100\n",
    "continent = ['Asia', 'Africa']\n",
    "searchfor = ['s', 'w']\n",
    "drinks[drinks.country.str.contains('|'.join(searchfor), case=False) & \n",
    "       drinks.continent.isin(continent) & \n",
    "       (drinks.beer_servings > 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging 2D x 1D arrays of different length\n",
    "\n",
    "Ref: [Stackoverflow: 30598281](https://stackoverflow.com/questions/30597260/merging-a-dataframe-with-a-series/30598281)\n",
    "\n",
    "The task is to repeat rows in the 2D array for values in the 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging a 2 dimensional master array with a one dimensional date series\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "# Create a 3 x 4 master dataframe\n",
    "df = pd.DataFrame(np.random.randn(3,4), columns = list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a key into the master dataframe\n",
    "df['key'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2 x 1 date series\n",
    "dates = pd.date_range(date.today(), periods=2)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the date series into a dataframe with the key \n",
    "ser = pd.DataFrame({'By': dates, 'key':[0] * len(dates)})\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the master dataframe and the dataseries dataframe over the key and drop the key. \n",
    "result = pd.merge(df, ser, on = 'key').drop('key', axis = 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup if date is between two dates from another dataframe\n",
    "The following lookup code evaluates if dates are between two dates and extracts the associated text (Weeknumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "dates = pd.date_range('20180101', periods=21)\n",
    "week_start = pd.date_range('20180101', periods=3, freq='W-Mon')\n",
    "week_end = pd.date_range('20180101', periods=3, freq='W-Sun')\n",
    "week = pd.Series(['W1', 'W2', 'W3'])\n",
    "df1 = pd.DataFrame({'By': dates, \n",
    "                    'SerNo': np.random.randint(5, size=21)})\n",
    "df2 = pd.DataFrame({'Start': week_start,\n",
    "                    'End': week_end,\n",
    "                    'Week': week})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text of the week\n",
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekends\n",
    "week_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of dates (contains 21 values)\n",
    "df1.loc[0:8,['SerNo', 'By']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of weekly buckets\n",
    "df2[['Start', 'End', 'Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array with Interval index of the weeks\n",
    "idx = pd.IntervalIndex.from_arrays(df2.Start, df2.End, closed='both')\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = df2.loc[idx.get_indexer(df1.By), 'Week']\n",
    "week[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Week'] = week.values\n",
    "df1.loc[0:10, ['SerNo', 'By', 'Week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup between two arrays and add records to master\n",
    "Ref: [StackOverflow: 46597513](https://stackoverflow.com/questions/46597513/splitting-order-quantities-by-type-and-scoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # This is required for indexing to ignore. Find+Replace nan to np.nan\n",
    "\n",
    "ask = [{'Date': '6-Oct-17', 'Qty': 80.0, 'Scoop': 'Single', 'Type': 'A'},\n",
    " {'Date': '10-Oct-17', 'Qty': 90.0, 'Scoop': 'Triple', 'Type': 'B'},\n",
    " {'Date': '9-Oct-17', 'Qty': 40.0, 'Scoop': 'Double', 'Type': 'D'},\n",
    " {'Date': '10-Oct-17', 'Qty': 20.0, 'Scoop': 'Double', 'Type': 'C'},\n",
    " {'Date': '10-Oct-17', 'Qty': 90.0, 'Scoop': 'Triple', 'Type': 'B'},\n",
    " {'Date': '9-Oct-17', 'Qty': 30.0, 'Scoop': 'Single', 'Type': 'A'}]\n",
    "\n",
    "ask = pd.DataFrame(ask)\n",
    "ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icecream = [{'Flavour1': 'Strawberry',\n",
    "  'Flavour2': np.nan,\n",
    "  'Flavour3': np.nan,\n",
    "  'Proportion': 0.25,\n",
    "  'Scoop': 'Single',\n",
    "  'Scoops/Tub': 4,\n",
    "  'Type': 'A'},\n",
    " {'Flavour1': 'Banana',\n",
    "  'Flavour2': 'Lemon',\n",
    "  'Flavour3': np.nan,\n",
    "  'Proportion': 0.25,\n",
    "  'Scoop': 'Double',\n",
    "  'Scoops/Tub': 2,\n",
    "  'Type': 'C'},\n",
    " {'Flavour1': 'Vanilla',\n",
    "  'Flavour2': 'Lemon',\n",
    "  'Flavour3': 'Mint',\n",
    "  'Proportion': 0.11,\n",
    "  'Scoop': 'Triple',\n",
    "  'Scoops/Tub': 3,\n",
    "  'Type': 'B'},\n",
    " {'Flavour1': 'Chocolate',\n",
    "  'Flavour2': 'Vanilla',\n",
    "  'Flavour3': np.nan,\n",
    "  'Proportion': 0.1,\n",
    "  'Scoop': 'Double',\n",
    "  'Scoops/Tub': 5,\n",
    "  'Type': 'D'}]\n",
    "\n",
    "icecream = pd.DataFrame(icecream)\n",
    "icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tub=ask.merge(icecream.drop('Scoop',1),on='Type',how='left')\n",
    "tub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tub=tub.set_index(['Date','Type','Scoop','Qty','Scoops/Tub','Proportion']).stack().reset_index()\n",
    "tub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tub['Qty']=tub['Qty']*tub['Proportion']\n",
    "tub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tub=tub.drop(['Scoops/Tub','Proportion','Scoop'],1).rename(columns={'level_6':'Scoop',0:'Flavour'})\n",
    "tub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if a date is inside or outside a specified date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a date is inside or outside a specified date range column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A': pd.date_range('20170101', periods=10),\n",
    "                    'B': pd.date_range('20170101', '20170310', freq=\"W-Fri\"),\n",
    "                    'C': pd.Timestamp('20170108')}); df\n",
    "                \n",
    "# df['Inside'] = np.where( (df['B'] > df['A']) & (df['B'] < df['C']), 'In' , 'Out'); df\n",
    "df['Inside'] = np.where( (df['B'] > df['A']) & (df['B'] < df['C']), df['B'] - df['A'] , df['A'] - df['A']); df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build arrays for sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.empty((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.full((2,2),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10,25,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.identity(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((5,5))*np.identity(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.lognormal(mean=0, sigma=1, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                           'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B' : ['one', 'one', 'two', 'three',\n",
    "                           'two', 'two', 'one', 'three'],\n",
    "                    'C' : np.random.randn(8),\n",
    "                    'D' : np.random.randn(8)})\n",
    "\n",
    "grouped = df.groupby(['A', 'B'])\n",
    "grouped.last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting variable number of pandas rows w.r.t. a dictionary lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, string\n",
    "\n",
    "max_rows = {'A': 3, 'B': 2, 'D': 4} # max number of rows to be extracted\n",
    "\n",
    "data_size = 1000\n",
    "\n",
    "df = pd.DataFrame({'symbol': pd.Series(random.choice(string.ascii_uppercase) \n",
    "                                       for _ in range(data_size)),\n",
    "              'qty': np.random.randn(data_size)}).sort_values('symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.loc[df[\"symbol\"].eq(k)].head(v) for k,v in max_rows.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Ticker symbols of S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = https.urlopen('GET', 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "symbols_table = pd.read_html(url.data, header=0)[0]\n",
    "symbols = list(symbols_table.loc[:, \"Ticker symbol\"])\n",
    "symbols_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "Best practice on classes and OOP in python (Ref: [jeffknupp.com](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customer(object):\n",
    "    \"\"\"A customer of ABC Bank with a checking account. Customers have the \n",
    "    following properites:\n",
    "    \n",
    "    Attributes:\n",
    "       name: A string representing the customer's name.\n",
    "       balance: A float tracking the current balance of the customer's account\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, balance=0.0):\n",
    "        \"\"\"Return a Customer object whose name is *name* and starting \n",
    "        balance is *balance*.\"\"\"\n",
    "        self.name = name\n",
    "        self.balance = balance\n",
    "        \n",
    "    def withdraw(self, amount):\n",
    "        \"\"\"Return the balance remaining after withdrawing *amount* \n",
    "        dollars.\"\"\"\n",
    "        if amount > self.balance:\n",
    "            raise RuntimeError('Amount greater than available balance.')\n",
    "        self.balance -= amount\n",
    "        return self.balance\n",
    "    \n",
    "    def deposit(self, amount):\n",
    "        \"\"\"Return the balance remaining after depositing *amount*\n",
    "        dollars.\"\"\"\n",
    "        self.balance += amount\n",
    "        return self.balance       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To call (instantiate) the class\n",
    "jeff = Customer('Jeff Knupp', 1000.0)    #jeff is the object, which is an iinstance of the *Customer* class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The *self* parameter in *Customer* methods performs the given instructions.\n",
    "# For e.g. to withdraw\n",
    "\n",
    "jeff.withdraw(100.0)   # Instruction to withdraw\n",
    "jeff.balance           # Shows 900.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to withdraw is by using the class name itself as follows:\n",
    "Customer.withdraw(jeff, 200.0)\n",
    "jeff.balance           # Shows 700.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(object):\n",
    "    \"\"\" A car with wheels, make and model\n",
    "    \n",
    "    Usage::     Car(make, model)\n",
    "    \n",
    "    Attr:\n",
    "       make: A string representing car company\n",
    "       model: a string representing the model of the car\n",
    "    \n",
    "    \"\"\"\n",
    "    wheels = 4\n",
    "    \n",
    "    def __init__(self, make, model):\n",
    "        \"\"\"Returns a Car object whose company is *make* and model is *model*\"\"\"\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "\n",
    "mustang = Car(\"Ford\", \"Mustang\")\n",
    "mustang.make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mustang.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mustang.wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Car.wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(object):\n",
    "    \"\"\" A car with wheels, make and model\n",
    "    \n",
    "    Usage::     Car(make, model)\n",
    "    \n",
    "    Attr:\n",
    "       make: A string representing car company\n",
    "       model: a string representing the model of the car\n",
    "    \n",
    "    \"\"\"\n",
    "    wheels = 4\n",
    "    \n",
    "    def __init__(self, make, model):\n",
    "        \"\"\"Returns a Car object whose company is *make* and model is *model*\"\"\"\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_car_sound():\n",
    "        print('Vrooooooooom!')\n",
    "\n",
    "mustang = Car(\"Ford\", \"Mustang\")\n",
    "mustang.make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Car.make_car_sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle(object):\n",
    "    \"\"\" A vehicle with wheels make and model\n",
    "    \n",
    "    Usage:: Vehicle(wheels, miles, make, model, year, sold_on)\n",
    "    \n",
    "    Attr:\n",
    "       wheels: An integer representing the number of wheels\n",
    "       miles: An integer with number of miles\n",
    "       make: A string representing car company\n",
    "       model: A string representing the model of the car\n",
    "       year: An integer year when the car was built\n",
    "       sold_on: Date when the vehicle was sold\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, wheels, miles, make, model, year, sold_on):\n",
    "        \"\"\"Return a new Vehicle object\"\"\"\n",
    "        self.wheels = wheels\n",
    "        self.miles = miles\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.sold_on = sold_on\n",
    "        \n",
    "    def sale_price(self):\n",
    "        \"\"\"Return the sale price for this vehicle as a float amount\"\"\"\n",
    "        if self.sold_on is not None:\n",
    "            return 0.0 # Already sold\n",
    "        return 5000.0 * self.wheels\n",
    "    \n",
    "    def purchase_price(self):\n",
    "        \"\"\"Return the price for which we would pay to purchase the vehicle\"\"\"\n",
    "        if self.sold_on is None:\n",
    "            return 0.0  # Not yet sold\n",
    "        return 8000 - (.10 * self.miles)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the vehicle (Still not DRY code !!!). Also shouldn't let Vehicle to be created. Only Cars and Trucks should be creatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(Vehicle):\n",
    "    \n",
    "    def __init__(self, wheels, miles, make, model, year, sold_on):\n",
    "        \"\"\"Return a new Car object\"\"\"\n",
    "        self.wheels = wheels\n",
    "        self.miles = miles\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.sold_on = sold_on\n",
    "        self.base_sale_price = 8000\n",
    "        \n",
    "class Truck(Vehicle):\n",
    "    \n",
    "    def __init__(self, wheels, miles, make, model, year, sold_on):\n",
    "        \"\"\"Return a new Truck object\"\"\"\n",
    "        self.wheels = wheels\n",
    "        self.miles = miles\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.sold_on = sold_on\n",
    "        self.base_sale_price = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vehicle(4, 0, 'Honda', 'Accord', 2014, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.purchase_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract Base Class (ABC)\n",
    "Use Abstract Base Class to abstract away some common data and behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Vehicle(object):\n",
    "    \"\"\"A vehicle for sale by Kashi's Dealership\n",
    "    \n",
    "    Usage:: \n",
    "    \n",
    "    Attr:\n",
    "       wheels: No of wheels of the vehicle - Integer\n",
    "       miles: No of miles driven on vehicle - Integer\n",
    "       make: Manufacturer of the vehicle - String\n",
    "       model: Model of the vehicle - String\n",
    "       year: Year when the vehicle was built - Integer\n",
    "       sold_on: Date when vehicle was sold - Date\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    base_sale_price = 0\n",
    "    wheels = 0\n",
    "    \n",
    "    def __init__(self, miles, make, model, year, sold_on):\n",
    "        \"\"\" Returns a new Vehicle object\"\"\"\n",
    "        self.miles = miles\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.sold_on = sold_on\n",
    "        \n",
    "    def sale_price(self):\n",
    "        \"\"\"Return the sale price for the vehicle - Float\"\"\"\n",
    "        if self.sold_on is not None:\n",
    "            return 0.0 # Already sold\n",
    "        return 5000.0 * self.wheels\n",
    "    \n",
    "    def purchase_price(self):\n",
    "        \"\"\"Return the price we would pay to purchase the vehicle - Float\"\"\"\n",
    "        if self.sold_on is None:\n",
    "            return 0.0 # Not yet sold\n",
    "        return self.base_sale_price - (0.10 * self.miles)\n",
    "    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def vehicle_type(self):\n",
    "        \"\"\"Returns type of vehicle - String\"\"\"\n",
    "        pass        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the *Car* and *Truck* classes become:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(Vehicle):\n",
    "    \"\"\"A car for sale by Kashi's dealership\"\"\"\n",
    "    \n",
    "    base_sale_price = 8000\n",
    "    wheels = 4\n",
    "    \n",
    "    def vehicle_type(self):\n",
    "        \"\"\"Return a string representing type of this vehicle - String\"\"\"\n",
    "        return 'car'\n",
    "    \n",
    "class Truck(Vehicle):\n",
    "    \"\"\"A truck for sale by Kashi's dealership\"\"\"\n",
    "    \n",
    "    base_sale_price = 10000\n",
    "    wheels = 4\n",
    "    \n",
    "    def vehicle_type(self):\n",
    "        \"\"\"Return a string representing type of this vehicle - String\"\"\"\n",
    "        return 'truck'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motorcycle(Vehicle):\n",
    "    \"\"\"A motorcycle for sale by Kashi's dealership\"\"\"\n",
    "    \n",
    "    base_sale_price = 4000\n",
    "    wheels = 2\n",
    "    \n",
    "    def vehicle_type(self):\n",
    "        \"\"\"Return a string representing type of this vehicle - String\"\"\"\n",
    "        return \"motorcycle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = Motorcycle(make='Honda', miles=2000, model='Hawk', sold_on=\"01-Feb-2008\",year=2007)\n",
    "mc.vehicle_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling Python Code\n",
    "[Easy Python Profiling](http://mortada.net/easily-profile-python-code-in-jupyter.html)\n",
    "\n",
    "\n",
    "Profiling Python code can be done by:\n",
    "1. %%time - for the whole code\n",
    "2. %%timeit - for repeated execution of single lines - or entire code. This doesn't give output\n",
    "3. %load_ext line_profiler\n",
    "+ %lprun -f function_name function_name(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing lexed contents of a python file in Jupyter\n",
    "\n",
    "Uses [Pygments](http://pygments.org/docs/quickstart/) Syntax highlighter\n",
    "<p><b>Note:</b> This has been put as a function in _utilities.py_</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import IPython\n",
    "\n",
    "def display_py(code):\n",
    "    \"\"\"Displays python file code in Jupyter\n",
    "    \n",
    "    Arg: (srting from py file) code\n",
    "    \n",
    "    Output: code formatted for jupyter\n",
    "    \n",
    "    Usage: with open(myfile) as f:\n",
    "                code = f.read()\n",
    "                \n",
    "           display_py(code)\n",
    "    \"\"\"\n",
    "    formatter = HtmlFormatter()\n",
    "    \n",
    "    html_code = highlight(code, PythonLexer(), HtmlFormatter())\n",
    "    styled_html = '<style type=\"text/css\">{}</style>{}'.format(formatter.get_style_defs('.highlight'), html_code)\n",
    "    ipython_code = IPython.display.HTML(styled_html)\n",
    "    \n",
    "    return ipython_code\n",
    "    \n",
    "with open('add_two_numbers.py') as f:\n",
    "    code = f.read()\n",
    "    \n",
    "display_py(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ib_insync code in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(options), 100):\n",
    "    for t in ib.reqTickers(*options[i:i+100]):\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...in list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for i in range(0, len(options), 100) for t in ib.reqTickers(*options[i:i+100])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catching errors in list comprehension\n",
    "Ref: [Stack Overflow: 1528237](https://stackoverflow.com/a/8915613/7978112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        return handle(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the list comprehension\n",
    "eggs = (1,3,0,3,2)\n",
    "[catch(lambda : 1/egg) for egg in eggs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataframes from a nested list\n",
    "Also used for making a dataframe from 3 lists of unequal lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_list = [('R1',\n",
    "  {'a', 'b', 'c'},\n",
    "  {20.0,   40.0,   50.0,   60.0,   750.0}),\n",
    " ('R2',\n",
    "  {'x', 'y', 'z'},\n",
    "  {35.0,   37.5,   165.0}), \n",
    " ('R3',\n",
    "  {'x', 'a', 'm'},\n",
    "  {2.5,   5.0,   7.5,   10.0,   12.5,   45.0})]\n",
    "\n",
    "nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  itertools import product\n",
    "\n",
    "L = [[[x[0]], sorted(x[1]), sorted(x[2])] for x in nested_list]\n",
    "pd.DataFrame([j for i in L for j in product(*i)], columns=['Cat','Column','Value']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting lambda into list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': 1, 'b': range(4)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumthis(a, b):\n",
    "    return a+b\n",
    "\n",
    "list(map(lambda x, y: sumthis(x, y), [i for i in df.a], [j for j in df.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In list cmprehension, zip is used:\n",
    "[sumthis(x, y) for x, y in zip(df.a, df.b)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup and Replace / Map data between a main dataframe and a lookup dataframe\n",
    "Ref: [StackOverflow](https://stackoverflow.com/questions/43716045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame({'A': list('abcd'),\n",
    "                        'B': list('lmno'),\n",
    "                        'C': list('efgh'),\n",
    "                        'D': list('qrst')})\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = pd.DataFrame({'X': range(4),\n",
    "                          'Lookup': list('ghqr'),\n",
    "                          'Val': [10,15,20,30]})\n",
    "\n",
    "lookup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of the lookup_df to Lookup column\n",
    "lookup_df = lookup_df.set_index('Lookup')\n",
    "lookup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map column C to replace its value with the lookup\n",
    "main_df.C = main_df.C.map(lookup_df.X)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using replace\n",
    "main_df.replace(main_df.D, main_df.D.map(lookup_df.X), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing volatility and comparing it with standard deviation\n",
    " Ref: [Motley Fool](https://www.fool.com/knowledge-center/how-to-calculate-annualized-volatility.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "Ser = pd.Series([1972.18, 1988.87, 1987.66, 1940.51, 1861.61, 1893.21, 1970.81, 2035.73, 2079.61, 2096.92, \n",
    "                 2102.44, 2091.54, 2083.39, 2086.05, 2084.07, 2104.18, 2077.57, 2083.56, 2099.84, 2093.32, 2098.04])\n",
    "Ser.expanding(1).std(ddof=1)  #outputs the rolling standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the percent change\n",
    "Ser.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the standard deviation of the percent change\n",
    "Ser.pct_change().std(ddof=0)  # This is 1.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get annualized volatility, multiply by no of trading days\n",
    "Ser.pct_change().std(ddof=0)*sqrt(252)  # This gives 27% annual volaility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get continuous annual volaility\n",
    "Ser.pct_change().expanding(1).std(ddof=0)*sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing empty lists / dicts [ ] / { } and nan from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "values = [dict(), [], 5, np.nan, 'a']*2\n",
    "keys = ['Key'+ str(i+1) for i in range(len(values))]\n",
    "\n",
    "my_dict = {}\n",
    "for i, key in enumerate(keys):\n",
    "    my_dict[key] = values[i]\n",
    "\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one gives a type error!\n",
    "[v for k, v in my_dict.items if v if str(v) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the correct way. First remove empty items, then check if the string has 'nan'\n",
    "{i: j for i, j in {k: v for k, v in my_dict.items() if v}.items() if str(j) != 'nan'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Wall Time in between programs\n",
    "Ref: [Stackoverflow](https://stackoverflow.com/a/14452178/7978112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "start = time()\n",
    "\n",
    "# put the code here\n",
    "sleep(2)\n",
    "\n",
    "codetime = time() - start\n",
    "\n",
    "m, s = divmod(codetime,60)\n",
    "h, m = divmod(m, 60)\n",
    "\n",
    "print('{:d}:{:02d}:{:02d}'.format(int(h), int(m), int(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making interactive pivotcharts from pandas dataframes\n",
    "(Ref: [https://towardsdatascience.com/two-essential-pandas-add-ons-499c1c9b65de](https://towardsdatascience.com/two-essential-pandas-add-ons-499c1c9b65de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "df = pd.read_csv('http://bit.ly/imdbratings')\n",
    "pivot_ui(df,outfile_path=\"./data/pivottablejs.html\")\n",
    "HTML(\"pivottablejs.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.python.org')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering rows by column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create python list of booleans with the same length of the dataframe. \n",
    "#Boolean will be true if it is > 200 mins and false if others\n",
    "booleans = []\n",
    "for length in movies.duration:\n",
    "    if length >= 200:\n",
    "        booleans.append(True)\n",
    "    else:\n",
    "        booleans.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(booleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert booleans list to a pandas series\n",
    "is_long = pd.Series(booleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass is_long to the dataframe movies with bracket notation\n",
    "movies[is_long].head()\n",
    "\n",
    "#It shows up dataframe with all columns but only shows those with duration > 200 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a shorter way - without the for loop.\n",
    "\n",
    "#Instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This completely replaces the need for a 'for' loop.\n",
    "is_long = movies.duration >= 200 # Series (movies.duration)  ... comparison >=200 and returns series of trues and falses\n",
    "is_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[is_long].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can eliminate is_long itself\n",
    "movies[movies.duration >=200].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are studying only the genre of the movies\n",
    "# you can use dot notation\n",
    "\n",
    "movies[movies.duration >=200].genre\n",
    "\n",
    "# or in bracket notations\n",
    "movies[movies['duration'] >=200]['genre']\n",
    "\n",
    "#The above code may sometimes cause strange behaviour. Not the best way to do things.\n",
    "#better practice is to use the .loc method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc with a comma\n",
    "movies.loc[movies['duration'] >=200, 'genre']\n",
    "\n",
    "#.loc allows selection of rows and columns by 'label'\n",
    "# in the above movies['duration'] >= 200 are the rows and 'genre' are the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...For Multiple filter criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.duration >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we select only long movies of genre Drama?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.duration >= 200 and movies.genre == 'Drama'] # will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parenthesis to add evaluation order\n",
    "# add ampersand & instead of and\n",
    "\n",
    "movies[(movies.duration >= 200) & (movies.genre == 'Drama')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or condition - gives a much bigger dataframe\n",
    "movies[(movies.duration >= 200) | (movies.genre == 'Drama')].head()\n",
    "movies[(movies.duration >= 200) | (movies.genre == 'Drama')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inside the bracket there is a boolean series which tells dataframe which rows display\n",
    "((movies.duration >= 200) & (movies.genre == 'Drama'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if there is a bunch of or conditions on the same series\n",
    "# either crime or drama or action\n",
    "# normally\n",
    "movies[(movies.genre == 'Crime') | (movies.genre == 'Drama') | (movies.genre == 'Action')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is very wordy.\n",
    "# to simplify we can use a series method called 'isin'\n",
    "# it generates a boolean series\n",
    "movies.genre.isin(['Crime', 'Drama', 'Action'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above series can be passed to the DataFrame\n",
    "movies[movies.genre.isin(['Crime', 'Drama', 'Action'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Scraping all HTMLs table from a URL using BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://www.5paisa.com/5pit/spma.asp\", verify=False)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "table = soup.find_all('table')\n",
    "df = pd.read_html(str(table))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Scraping an HTML table into pandas\n",
    "import pandas as pd\n",
    "url = \"https://www.5paisa.com/5pit/spma.asp\"\n",
    "df = pd.read_html(url)[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html\n",
    "import requests\n",
    "\n",
    "url = \"https://finance.google.com/finance?q=NSE:PFC\"\n",
    "\n",
    "page = requests.get(url)\n",
    "root = html.fromstring(page.content)\n",
    "dividend = float(root.findall('.//table')[2].text_content().strip().split(\"\\n\")[2].split('/')[0])\n",
    "dividend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of loc and iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas Index\n",
    "## ...from Data School - ref: https://www.youtube.com/watch?v=OYZNk7Z9s6I\n",
    "import pandas as pd\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('http://bit.ly/movieusers', header = None, sep = '|').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks[drinks.continent == 'South America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[23, 'beer_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.set_index('country', inplace=True)\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc['Brazil', 'beer_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index.name = None\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index.name = 'country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.describe().loc['25%', 'beer_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.set_index('country', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts()['Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.Series([3000000, 85000], index=['Albania', 'Andorra'], name = 'population')\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.beer_servings * people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([drinks, people], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(drinks.continent.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks['continent'] = drinks.continent.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.cat.codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks['country'] = drinks.country.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.country.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling date and time in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sightings by year or time\n",
    "# Check the dtypes\n",
    "ufo.dtypes # time column shows an object - in this case a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.str.slice(-5, -3).head()  #outputs as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.str.slice(-5, -3).astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above approach is very brittle. It easily breaks\n",
    "# overwrite the time column. Overwrite the Time column.\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real thing that's changed is dtype is now datetime\n",
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas just figures out the date. If not, there are lot of options in to_datetime\n",
    "ufo.Time.dt.hour # Pulls out the hour\n",
    "ufo.Time.dt.weekday_name[:4] # Pulls out the name of the week!\n",
    "# Search the reference page for '.dt.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pass a string instead of a series\n",
    "pd.to_datetime('1/1/1999') #outputs a timestamp. Did not have to specify month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.to_datetime('1/1/1999') # Save it for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[ufo.Time >= ts, :].head() #only shows othe ufo's sighted after 1/1/1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do math operations\n",
    "ufo.Time.max() # Latest timestamp in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.max() - ufo.Time.min() # time delta object tells the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timedelta objects have attributes like .days\n",
    "(ufo.Time.max() - ufo.Time.min()).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of ufo reports by year. Plot!\n",
    "%matplotlib inline\n",
    "ufo['Year'] = ufo.Time.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Year.value_counts().sort_index().plot()  #sort by order of index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling inputs in date format\n",
    "Following code converts any text input to appropriate date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "while True:\n",
    "    expiry = input('Expiry: ')\n",
    "    try:\n",
    "        parse(expiry)\n",
    "    except ValueError:\n",
    "        print(\"Enter date in any proper format\")\n",
    "    expiry = parse(expiry)\n",
    "    break\n",
    "\n",
    "expiry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# x = ['~', 'A', 'Sun']   # Works\n",
    "x = ['~', 'Walter', 'A', 'Sun'] # Doesn't work because of Walter \n",
    "df = pd.DataFrame(x, columns=['x'])\n",
    "\n",
    "u = \"https://en.wikipedia.org/wiki/\"\n",
    "\n",
    "df['URL'] = u + df['x']\n",
    "\n",
    "def tbl10(u):\n",
    "    html = requests.get(u).content\n",
    "    tbl = pd.read_html(u)[10]\n",
    "    return tbl\n",
    "\n",
    "v = np.vectorize(tbl10)\n",
    "pd.concat(v(df.URL))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try-Except Error detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        x = int(input(\"Please enter a number: \"))\n",
    "        break\n",
    "    except ValueError:\n",
    "        pass\n",
    "        print(\"Oops! That was no valid number. Try again...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df % 3 == 0\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map and Apply experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate sex to 1 and 0 using map\n",
    "train['Sex_num'] = train.Sex.map({'female':0, 'male':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare sex and sex num\n",
    "train.loc[0:4, ['Sex', 'Sex_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use apply method for a function\n",
    "train['Name_len'] = train.Name.apply(len)\n",
    "\n",
    "train.loc[0:4, ['Name', 'Name_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train['Fare_ceil'] = train.Fare.apply(np.ceil)\n",
    "\n",
    "train.loc[0:4, ['Fare', 'Fare_ceil']]\n",
    "\n",
    "train.Name.str.split(',').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "\n",
    "train.Name.str.split(',').apply(get_element, position=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Name.str.split(',').apply(lambda x: x[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(np.argmax, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings']=drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float)\n",
    "\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varargs(*args):\n",
    "    return args\n",
    "\n",
    "varargs(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_args(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "keyword_args(big=\"foot\", loch=\"ness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_the_args(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "\n",
    "all_the_args(1, 2, a=3, b=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (1, 2, 3, 4)\n",
    "kwargs = {\"a\": 3, \"b\": 4}\n",
    "all_the_args(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_args(*kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_args(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_args(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average beer servings\n",
    "drinks.beer_servings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beer servings by continent\n",
    "drinks.groupby('continent').beer_servings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does the work. Let us filter and see\n",
    "drinks[drinks.continent == 'Africa'].beer_servings.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When to use groupby?\n",
    "When there is a need to analyze by category (e.g. continent)\n",
    "\n",
    "...if there is a need 'for each'\n",
    "for each continent what is beer serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are other functions too... e.g. max, min, etc.\n",
    "drinks.groupby('continent').beer_servings.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even powerful is .agg ... allows multiple aggregation functions\n",
    "drinks.groupby('continent').beer_servings.agg(['count', 'min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no aggregation is specified, it aggregates all numeric values\n",
    "drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display in visual\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.groupby('continent').mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to display the groups?\n",
    "g = drinks.groupby('continent')\n",
    "for continent, continent_df in g:\n",
    "    print(continent)\n",
    "    print(continent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the specific dataframe\n",
    "g.get_group('Africa').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The concept is of split, apply and combine\n",
    "drinks.groupby('continent').agg('max')  # groupby is split, agg is apply and max is combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives all the detaiils\n",
    "g.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ib_insync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***          Start ib_insync (run once)       *****\n",
    "#_______________________________________________\n",
    "\n",
    "from ib_insync import *\n",
    "util.startLoop()\n",
    "# ib = IB().connect('127.0.0.1', 3000, clientId=0) # kavi tws live\n",
    "# ib = IB().connect('127.0.0.1', 3000, clientId=0) # kavi IBG live\n",
    "\n",
    "# ib = IB().connect('127.0.0.1', 1300, clientId=0) # rkv tws live\n",
    "# ib = IB().connect('127.0.0.1', 1300, clientId=0) # rkv IBG live\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******         Paths and variables         ****\n",
    "#_______________________________________________\n",
    "\n",
    "datapath = r'./zdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error catching in list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******   Error catch in list comprehension  ****\n",
    "#________________________________________________\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    '''List comprehension error catcher'''\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Standard Deviation for an NSE scrip\n",
    "This function gets price for NSE scrips from IBKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Get the scrip\n",
    "symbol = 'RELIANCE'\n",
    "contract = ib.qualifyContracts(Stock(symbol, exchange))[0]\n",
    "\n",
    "#... Get stdev, hi52 and lo52\n",
    "duration = '12 M'\n",
    "size = '1 day'\n",
    "bars = ib.reqHistoricalData(contract=contract, endDateTime='', \n",
    "                     durationStr=duration, barSizeSetting=size, \n",
    "                     whatToShow='TRADES', useRTH=True, \n",
    "                     formatDate=1, keepUpToDate=True)\n",
    "\n",
    "stDev = np.std(a=[b.close for b in bars], ddof=0)\n",
    "\n",
    "hi52 = max([b.high for b in bars])\n",
    "lo52 = min([b.low for b in bars])\n",
    "\n",
    "meanPrice = np.mean([b.close for b in bars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get option prices with greeks (via tickers)\n",
    "The best way to extract greeks and prices for options is to get them through the option chain and expiries as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Get the scrip\n",
    "symbol = 'RELIANCE'\n",
    "contract = ib.qualifyContracts(Stock(symbol, exchange))[0]\n",
    "\n",
    "#... Get the option chain tickers\n",
    "chains = ib.reqSecDefOptParams(underlyingSymbol=contract.symbol, \n",
    "                      futFopExchange='', \n",
    "                      underlyingConId=contract.conId, underlyingSecType=contract.secType)\n",
    "\n",
    "expiries = set(*[c.expirations for c in chains])\n",
    "\n",
    "cds = [ib.reqContractDetails(Option(symbol, e, exchange='NSE')) for e in expiries]\n",
    "\n",
    "options = [c.contract for cs in cds for c in cs]\n",
    "\n",
    "tickers = [t for i in range(0, len(options), 100) for t in ib.reqTickers(*options[i:i + 100])]    \n",
    "ib.sleep(5)   # gives some time to fill the tickers    \n",
    "tickers = [t for i in range(0, len(options), 100) for t in ib.reqTickers(*options[i:i + 100])]\n",
    "\n",
    "# keep only those tickers with underlying prices\n",
    "lib_t = {t: utils.catch(lambda: t.modelGreeks.undPrice) for t in tickers}\n",
    "und_t = [k for k, v in lib_t.items() if v is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate list of datetimes\n",
    "datetimes = pd.date_range(start=\"2013-05-18 12:00:00\", periods=10, freq='m', tz=\"Europe/Brussels\")\n",
    "datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert them to Singapore time\n",
    "# check this out https://stackoverflow.com/questions/14004545\n",
    "pd.Series(datetimes).dt.tz_convert('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python38132bit2115ca79f6634adbad3a74c57c1d7c04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
